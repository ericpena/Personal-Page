<!DOCTYPE html>
<html lang="en">
  <head>
  <meta http-equiv="content-type" content="text/html;charset=utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="robots" content="noodp"/>
  
  <link rel="prev" href="https://ericpena.github.io/2019/speed-walking/" />
  <link rel="next" href="https://ericpena.github.io/2019/ga-intro/" />
  <link rel="canonical" href="https://ericpena.github.io/2019/complexity-reflection-1/" />
  <link rel='shortcut icon' type='image/x-icon' href='/favicon/favicon.ico' />
  <link rel="apple-touch-icon" sizes="180x180" href="/favicon/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="manifest" href="/favicon/site.webmanifest">
  <link rel="mask-icon" href="/favicon/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">
  <title>
       
       
           Complexity — A Guided Tour Reflection | Eric Peña
       
  </title>
  <meta name="title" content="Complexity — A Guided Tour Reflection | Eric Peña">
    
  
  <link rel="stylesheet" href="/font/iconfont.css">
  <link rel="stylesheet" href="/css/main.min.css">


  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Complexity — A Guided Tour Reflection"/>
<meta name="twitter:description" content="Reflection Paper"/>

  <script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BlogPosting",
  "headline": "Complexity — A Guided Tour Reflection",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://ericpena.github.io/2019/complexity-reflection-1/"
  },
  "image": {
    "@type": "ImageObject",
    "url": "https://ericpena.github.io/cover.png",
    "width": 800,
    "height": 600
  },
  "genre": "posts",
  "keywords": "Networks, Mathematics, Complex Systems",
  "wordcount": 2433,
  "url": "https://ericpena.github.io/2019/complexity-reflection-1/",
  "datePublished": "2019-08-26T00:00:00+00:00",
  "dateModified": "2019-08-26T00:00:00+00:00",
  
  "publisher": {
    "@type": "Organization",
    "name": "Fastbyte01",
    "logo": {
      "@type": "ImageObject",
      "url": "https://ericpena.github.io/logo.png",
      "width": 127,
      "height": 40
    }
  },
  "author": {
    "@type": "Person",
    "name": "Fastbyte01"
  },
  "description": "Reflection Paper"
}
</script>

</head>

  


  <body class="">
    <div class="wrapper">
        <nav class="navbar">
    <div class="container">
        <div class="navbar-header header-logo">
        	<a href="https://ericpena.github.io">Eric Peña</a>
        </div>
        <div class="menu navbar-right">
                
                
                <a class="menu-item" href="/posts/" title="">Blog</a>
                
                <a class="menu-item" href="/categories/" title="">Categories</a>
                
                <a class="menu-item" href="/about" title="">About</a>
                
                <a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-sun"></i></a>&nbsp;
        </div>
    </div>
</nav>
<nav class="navbar-mobile" id="nav-mobile" style="display: none">
     <div class="container">
        <div class="navbar-header">
            <div>  <a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-sun"></i></a>&nbsp;<a href="https://ericpena.github.io">Eric Peña</a></div>
            <div class="menu-toggle">
                <span></span><span></span><span></span>
            </div>
        </div>
     
          <div class="menu" id="mobile-menu">
                
                
                <a class="menu-item" href="/posts/" title="">Blog</a>
                
                <a class="menu-item" href="/categories/" title="">Categories</a>
                
                <a class="menu-item" href="/about" title="">About</a>
                
        </div>
    </div>
</nav>
    	 <main class="main">
          <div class="container">
      		
<article class="post-warp">
    <header class="post-header">
        <h1 class="post-title">Complexity — A Guided Tour Reflection</h1>
        <div class="post-meta">
              <a href="https://ericpena.github.io" rel="author">Eric Peña</a>  ♥ 
                <span class="post-time">
                     <time datetime=2019-08-26 >26 August 2019</time>
                </span>
                
                <i class="iconfont icon-folder"></i>
                <span class="post-category">
                        <a href="https://ericpena.github.io/categories/complex-systems/"> Complex Systems </a>
                        
                </span>
                &nbsp;&nbsp;12 min
        </div>
    </header>
    <div class="post-content">
        

        
            
        

        
        
     
          
          
          

          
          
          

          

<p><img src="/img_complex/complex.png" alt="Complexity_Img" width="300"></p>

<h1 id="part-i">Part I:</h1>

<p>Providing the multifaceted story of how complex systems has evolved into what it is today is no easy feat. Dr. Melanie Mitchell not only gives a comprehensive historical tour of science and mathematics, she also provides foundational knowledge that any reader can carry to appreciate the essence of what it means for a system to be complex in the technical sense. Early on, she gives a clear definition of complex systems as an interdisciplinary field that studies how large networks of entities with no central controller can organize themselves and exhibit collective behavior given simple rules. However, she also humbly confesses that given how nebulous the field is, there has yet to be one clear definition of complexity that everyone can agree on. I appreciate how candid she is about what is known and what is not known in this field. Mitchell shares that even a panel she organized of great system science thinkers at the Santa Fe Institute could not agree on an answer to the question: &ldquo;how do you define complexity?&rdquo;.</p>

<p>She acknowledges the potential skepticism that one might feel because of the nascence of this field. However, she encourages the reader by sharing fascinating real-world examples&mdash;such as ant colonies, brain activity, and internet networks&mdash;that show the ubiquity of complex systems and its necessity in understanding how systems evolve in our lives. She eloquently describes the emergent collective behavior that arises from these systems and the wide scale at which they occur. From thoughts and consciousness in the brain to global economic market movements, these can all be thought of as emergent phenomena attributed to complexity. She mentions that some have even call these systems superorganisms that exhibit a collective intelligence even in non-living, non-conscious systems. She borrows examples from economics stating that the self-interest of smaller economic entities such as companies and individuals create macroscopic effects that tend to not resemble the smaller systems at all. I appreciate that complex systems are not only accessible to all of us everywhere we are, but also require them to survive such as brain neuroactivity and heartbeat rhythms.</p>

<p>Given my background, the section on dynamics, chaos, and prediction resonated with me most. Mitchell beautifully tells the story of how the natural world was analyzed by great scientists in history and how our understanding of nature evolved. This historical account builds from Aristotle, Copernicus, Galileo, Kepler, and finally Isaac Newton and his revolutionary laws of motion. Newton established a concept of universality extending the natural laws from the terrestrial realm to celestial bodies&mdash;one of the most enlightening realizations in science.</p>

<p>When I consider physics paradigms in the context of complexity, I think about the dismantling of reductionism&mdash;where the notion that a system is the sum of its parts, as is the case in classical mechanics&mdash;is no longer valid. Mitchell does not talk much about reductionism directly but instead touches on a topic much richer on how concepts in physics directly led to the understanding of complexity and its causes. Much of physics is used primary to make predictions but Mitchell mentions two important scientific discoveries that make prediction very difficult: the uncertainty principle from quantum mechanics and the sensitivity of initial conditions from chaos theory. In 1927, Heisenberg taught us that the momentum and position of a particle cannot be known simultaneously but rather act as a trade-off of information. This is not an experimental limitation but an inherent limitation of information that is written into the law of physics. This must have been devastating during the time of Newton&rsquo;s &ldquo;clockwork universe&rdquo; when mathematicians such as Pierre Simon Laplace had ideas of being able to, in theory, predict everything at all times given we have the information to do so. The development of chaos theory by Poincar\&lsquo;e and Lorenz had a similar effect stating that even the tiniest variation in initial conditions can lead to drastically different outcomes&mdash;which served as another blow to predictability.</p>

<p>Mitchell sheds hope and motivates the reader by mentioning that in the same way there are universal laws in physics, there are similar invariants in the study of complex systems as well. Period-doubling as a system evolves to a chaotic state and the Feigenbaum&rsquo;s constant for the rate at which bifurcations converge are examples of remarkable invariant properties in complex systems. This provides an indication that the essence of physics can likely be applied to the field of complex systems and even possibly toward its version of a unified theory.</p>

<p>Dr. Melanie Mitchell seamlessly weaves together the concepts of information, entropy, energy, and thermodynamics. These are integral to the field so much so that she even refers to &ldquo;entropy-defying self-organization&rdquo; as the &ldquo;holy grail of complex systems&rdquo;. She resolves the misconception that entropy can at times decrease without consequence even though the law of thermodynamics forbids it. She talks about this in terms of Maxwell&rsquo;s Demon stating that work is required for the demon to do its job. I had learned about Maxwell&rsquo;s Demon in the past but had never considered this in terms of information. Szilard thought that work and energy was expended when obtaining the measurements of the particle&rsquo;s velocities&mdash;in other words, it requires work to obtain the relevant information needed. I find this to be a novel idea and a clever way to connect all of these concepts in one easy to understand example.</p>

<p>Another pivotal moment for me in reading Part I was in chapter 4&mdash;computation. In the same way that physics endured a disillusionment of endless predictability, mathematics and computability had a relatable event in history through the work of Kurt Gödel and Alan Turing.
David Hilbert&rsquo;s provocative questions for the mathematics community challenged the stability of mathematics itself. Gödel figured out how to convert statements into mathematical language and learned that there exists self-contradictory mathematical statements&mdash;showing that not everything in mathematics could be proven. Mathematics was viewed as being exacting and able to prove anything at that time. Gödel&rsquo;s Incompleteness Theorem shattered the apparent grandeur of mathematics and worried many practitioners. Alan Turing also came up with a similar answer using what was called a Turing Machine. The result had extended to machine language as well.</p>

<p>Dr. Mitchell is not only able to clearly explain a topic as abstruse as complex theory, she does so to a general audience without inundating the reader with technical jargon. Since there is not a definition of complexity that the scientific community can agree on, Mitchell offers some thoughts about possible ways that complexity could be defined. She is again very candid about the limitations of these definitions and explains why they would not hold up in isolation. All throughout Part I, she keeps the theme of being informative, honest, and motivating. She is honest about scientists not yet having a clear understanding of the field but also offers other examples in history where this was also true such as the concept of energy before it was well understood. Even today, research on genes and dark matter have yet to be understood fully but are making tremendous progress. I learned a great deal so far from this book and I look forward to the insight it has to offer in the remaining chapters.</p>

<h1 id="parts-ii-and-iii">Parts II and III</h1>

<p>Melanie Mitchell states that it is hypothesized that the balance between exploration and exploitation of information may serve as a general property of what are now called complex systems. Having read parts II and III of the book, it is evident that this idea could not have been developed without the use of computation, particularly self-replicating systems. Mitchell takes us deeper into the journey of complex systems and focuses on the connection between computation and living systems. From the fine details of a genetic algorithm to large-scope philosophical ideas, she provides different levels of abstraction allowing the reader to appreciate these topics from all angles. The historical account she gives of evolutionary computation reads as if she is alluding to the past and the future almost simultaneously &mdash; she tells where the inspiration has come from and where it could lead.</p>

<h3 id="self-replication">Self Replication</h3>

<p>Part II begins with the idea of <strong><em>what life is</em></strong> and what are its properties. Mitchell explains how the idea of self-replicating artificial life is an old idea but continues to live on, even in our movies and artwork today. I thought this was a great introduction to the idea of evolutionary programming. The discussion leads to the idea of reproduction of computer systems that can, for example, print their own code. This is a novel idea on a fundamental level and a great zeroeth-order example to begin understanding its significance; but the fact that DNA, for example, can actually transcribe its own interpreter may provoke one to admit: some systems actually are <em>living</em>.</p>

<h3 id="genetic-algorithms">Genetic Algorithms</h3>

<p>I was inspired by the chapter on genetic algorithms to create my own program&mdash;a simple program that evolves and learns to print the characters:
<strong>ericpena</strong>. Although a simple task for a computer to perform, it made apparent the power of this methodology to solve more complicated tasks. John von Neumann is essentially the person who established the idea of self-replicating machines in a tangible way. Although, he thought that replication was not enough as these systems also need to evolve, learn, and compete with one another to survive. It was John Holland that proposed the idea for genetic algorithms that was inspired by how nature evolves to find near-optimal solutions via natural selection. Mitchell gives a great example on how a genetic algorithm can help improve the performance of Robby, the Soda-Can-Collecting Robot. This chapter revealed the vast potential for genetic algorithms and how in many ways they are better than human-developed algorithms for various tasks. One particular discussion that stood out to me regarding Robby is the following: Robby&rsquo;s success isn&rsquo;t necessarily dependent on the individual, step-by-step decisions that Robby makes to collect cans but rather the aggregate of these steps that define a hollistic strategy, a rather successful strategy at that. Mitchell explains this by stating that it isn&rsquo;t always individual genes at work but rather their interactions that produce results.</p>

<h3 id="cellular-automata-and-the-nature-of-computability">Cellular Automata and The Nature of Computability</h3>

<p>I have been enthralled by cellular automata ever since I first learned about them. In this chapter, Mitchell talks about how computation occurs in nature and what it even means for nature to &ldquo;compute&rdquo;. Similar to the way in which physicists simplify problems to gain understanding&mdash;through frictionless slopes and spherical cows&mdash;scientists have performed a simplification for computation in the form of cellular automata. Although the rules of a cell can be relatively simple, the interconnectedness of a grid of cells can produce complex behavior that can, at times, simulate natural processes such as forest fires, fire flies, and even neurons. The field of cellular automata seemed to have taken a life of its own. John von Neumann, who played a key role in creating cellular automata, proved that it is actually Turing Complete. John Conway&rsquo;s Game of Life programs popularize the discipline even further especially when proving that his game is capable of simulating a universal computer. With the large number of configurations and possibilities, it may have been difficult to wrap one&rsquo;s head around the innate behavior of this mechanism. It was Stephan Wolfram, who nothing short of genius, worked diligently and cleverly to classify the ways in which cellular automata can behave and what patterns it can exhibit. He created libraries of patterns for these things, particularly four classes, and became rather popular for his book on them, {\it A New Kind of Science}. I learned about Wolfram during my undergraduate program and used Mathematica for many of my homework problems&mdash;although I had not read about his beliefs that Mitchell mentions in the reading. I found it interesting that Wolfram believes natural processes are intrinsically computable and can be explained in this way. While in physics, I conceded to the idea that nature is infinitely complex and our best hope in grasping it is to make very accurate approximations with efforts such as quantum mechanics or Einsteinian gravity. However, Mitchell explains that Wolfram believes that nothing can be more complex than a universal computer which forces an upper limit on the complexity that the universe can exhibit&mdash;this is very interesting although I am not sure I agree completely given the unpredictability we read about earlier in the book, particularly in quantum mechanical phenomena. I was nevertheless fascinated by these ideas and will revisit them in the future.</p>

<p>A connection became apparent to me while reflecting on the chapters on genetic algorithms and cellular automata.  On one hand, many processes in nature consists of simple rules but large in number that coalesce into complex behavior. Cellular automata has this idea built into its very structure. In a way, we can say that the mechanism by which nature evolves and produces complexity is comparable to the way in which cellular automata does so. On the other hand, genetic algorithms were inspired by what occurs in nature, namely natural selection and evolution. I found it fascinating that nature utilizes general principles found in cellular automata and that genetic algorithms mimic what is done in nature. This further reinforces the link between computation and living systems.</p>

<h3 id="information-processing">Information Processing</h3>

<p>Mitchell guides the reader in understanding information processing particularly in living systems. I enjoyed how she uses different levels of programming, high level and machine language, to home in on the concept of abstraction. She mentions that it&rsquo;s relatively easy to imagine how changes in high level code are translated into low level machine language since the tether between the two is tangible and somewhat predictable. She compares this to cellular automata where the ability to create a productive level of abstraction is not present. This is particular to cellular automata but I imagine that it is a limitation that can be applied to much of complex systems as a whole&mdash;this is, creating a high level framework from which many applications can benefit from especially biological applications.
The book wonderfully explains information processing both in terms of what information is and how it is processed. It accomplishes this with the help of three real-world examples: the immune system, ant colonies, and biological metabolism. One of my favorite parts&mdash;which Mitchell believes is a quite profound idea&mdash;is that on the {\it meaning} of information. We can think in terms of inputs and outputs but what does the information {\it mean} and what part of a system is doing this type of analysis? As Mitchell points out, this is particularly mysterious for systems with no central controller.</p>

    </div>

    <div class="post-copyright">
             
            <p class="copyright-item">
                <span>:</span>
                <span>Eric Peña </span>
                </p>
            
           
            <p class="copyright-item">
                    <span>:</span>
                   <span>2433</span>
            </p>

             
            <p class="copyright-item lincese">
                Released under <a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a>
            </p>
            
    </div>

  
    <div class="post-tags">
        
            <section>
            <i class="iconfont icon-icon-tag"></i>: 
            
            <span class="tag"><a href="https://ericpena.github.io/tags/networks/">
                    #Networks</a></span>
            
            <span class="tag"><a href="https://ericpena.github.io/tags/mathematics/">
                    #Mathematics</a></span>
            
            <span class="tag"><a href="https://ericpena.github.io/tags/complex-systems/">
                    #Complex Systems</a></span>
            
            </section>
        
        <section>
                <a href="javascript:window.history.back();"></a></span> · 
                <span><a href="https://ericpena.github.io"></a></span>
        </section>
    </div>

    <div class="post-nav">
        
        <a href="https://ericpena.github.io/2019/speed-walking/" class="prev" rel="prev" title="Speed Walking in Chicago"><i class="iconfont icon-dajiantou"></i>&nbsp;Speed Walking in Chicago</a>
         
        
        <a href="https://ericpena.github.io/2019/ga-intro/" class="next" rel="next" title="First Genetic Algorithm — Prints: ericpena">First Genetic Algorithm — Prints: ericpena&nbsp;<i class="iconfont icon-xiaojiantou"></i></a>
        
    </div>

    <div class="post-comment">
          
                 
          
    </div>
</article>
          </div>
		   </main>
      <footer class="footer">
    <div class="copyright">
        
        &copy;
        
        
        <span itemprop="copyrightYear">2019</span>
        
        
        
            <span class="author" itemprop="copyrightHolder"><a href="https://ericpena.github.io">Eric Peña</a> | </span>
        

		  <span>Crafted with Hugo and GithubPages</span>
    </div>
    
    
    

    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\[','\]']],
            processEscapes: true,
            processEnvironments: true,
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            TeX: { equationNumbers: { autoNumber: "AMS" },
                 extensions: ["AMSmath.js", "AMSsymbols.js"] }
          }
        });
    </script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</footer>












    
     <link href="//lib.baomitu.com/lightgallery/1.6.11/css/lightgallery.min.css" rel="stylesheet">  
      
     <script src="/js/vendor_gallery.min.js" async="" ></script>
    
  











     </div>
  </body>
</html>
