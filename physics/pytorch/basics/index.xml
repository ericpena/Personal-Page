<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>physics - Eric Pe√±a</title>
    <link>https://ericpena.github.io/physics/pytorch/basics/index.xml</link>
    <description></description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
        <atom:link href="https://ericpena.github.io/physics/pytorch/basics/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Check If PyTorch Is Using The GPU</title>
      <link>https://ericpena.github.io/physics/pytorch/basics/check_if_pytorch_is_using_gpu.html</link>
      <pubDate>Sat, 01 Feb 2020 00:00:00 -0700</pubDate>
      
      <guid>https://ericpena.github.io/physics/pytorch/basics/check_if_pytorch_is_using_gpu.html</guid>
      <description>I find this is always the first thing I want to run when setting up a deep learning environment, whether a desktop machine or on AWS. These commands simply load PyTorch and check to make sure PyTorch can use the GPU.
Preliminaries # Import PyTorch import torch Check If There Are Multiple Devices (i.e. GPU cards) # How many GPUs are there? print(torch.cuda.device_count()) 1 Check Which Is The Current GPU? # Which GPU Is The Current GPU?</description>
    </item>
    
  </channel>
</rss>